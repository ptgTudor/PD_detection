# 2. The dataset

The dataset used in this project is comprised of recordings of 50 individuals diagnosed with Parkinson’s Disease and 50 individuals without the disease and without any symptoms associated with the disease that could raise any doubts, split evenly by gender in 25 men and 25 women, all native speakers of Colombian Spanish gathered at the Clínica Noel in Medellín, Colombia, under noise controller conditions within a specifically constructed soundproof booth.

The recordings were sampled at 44.1 kHz with a resolution of 16 bits, with the help of an omnidirectional microphone. The patients had their diagnosis assessed by specialists through the Unified Parkinson’s Disease Rating Scale (UPDRS) and the Hoehn and Yahr scale (H&Y) and the samples were taken from them shortly after receiving their morning medication.

UPDRS is graded by taking into account 4 parts: mood, daily activities, motor examinations and complications. Each category has several items that are graded between 0 and 4 points, with 0 being normal and 4 being severe, hence higher scores indicate more advanced stages of the disease.

H&Y is evaluated through 5 stages, with 2 intermediary ones added in a modified version from impairments affecting select movements and balance through inability to walk unassisted.

![image](https://github.com/user-attachments/assets/e03b977b-006b-4cba-a159-bc9aa74f11f8)
<center>Age, UPDRS and H&Y scores and time after diagnosis compared to healthy controls for men and women</center>

The age of Parkinson’s disease patients for men is between 33 and 77, with a mean age of 62.2 and a standard deviation of 11.2, while for the healthy men controls, the age is between 31 and 87, with a mean age of 61.2 and a standard deviation of 11.3. The age of the women patients is between 44 and 75 years old, with a mean age of 60.1 and a standard deviation of 7.8, while for the healthy women controls the age is between 43 and 76 years old, with a mean age of 60.7 and a standard deviation of 7.7.

The dataset consisted of multiple experiments, such as the uttering of sustained vowels, the diadochokinetic analysis, the uttering of modulated vowels (changing the tone from low to high), monologue samples where each participant talked about their day, the reading of passages of text as well as sentences and the pronunciation of select words.

Out of the dataset, two experiments were chosen for this project. One is the diadochokinetic analysis, since it yielded satisfying results and can easily be reproduced across multiple languages of international circulation. It consists of 6 tests where the following syllables are repeated:
• “ka-ka-ka”
• “pakata”
• “pa-pa-pa”
• “pataka”
• “petaka”
• “ta-ta-ta”

The other experiment consists of uttering 5 vowels (“A”, “E”, “I”, “O” and “U”) in a sustained manner, because they have similar pronunciation inside the Romance languages family, making it suitable for testing in a reasonably large area.

While the tests involving Spanish speech may offer good insights into the diagnosis, they were dropped because the aim of this project is to make the diagnosing process available on larger scales than solely the Spanish speaking countries.

As for the modulated vowels experiments, they were dropped due to considerations of difficulties in pronunciation for new subjects.

## 2.1 Dataset adjustments

One of the first observations that was made during this project was that a frequency of 44.1 kHz was not necessarily needed, since most of the signal components were in the 300 – 3400 Hz band and keeping the initial frequency would only lead to longer processing times.

So, according to the Nyquist theorem, the sampling frequency of these files would need to be at least twice the highest frequency component to maintain the accuracy of the recording. At first sight, a frequency of 8 kHz would appear sufficient. However, upon closer examination of some of the files, it was found that some of them did have components at over 4 kHz, albeit smaller compared to the rest of the file. Thus, it was deemed appropriate to convert the dataset files to 16 kHz frequency, trading unnoticeable accuracy gains for considerably faster processing times. In the images below, the spectral representation of some of the files can be seen.

## 2.2 Dataset augmentation

Since a dataset of samples collected only from 100 participants in a heavily controlled environment with highly performing equipment, enlarging the dataset through the previously discussed audiomentations library was one of the priority measures.

Noise was added with the AddGaussianSNR parameter, which adds a random value of Gaussian noise, selected from the bell shaped distribution given by minimum and maximum values, to the audio sample.

The effects of a room were created with the RoomSimulator parameter, which simulates a room of certain dimensions, whose boundaries may absorb part of the signal, taking into account the position of the speaker relative to the microphone.

Alteration of the speed or duration of the signal was done with the help of the TimeStretch parameter, although the values for this parameter were chosen so that the result would only have slight differences compared to the original file, because the quality would suffer for larger stretch values.

The PitchShift parameter was added to make the audio sounds slightly higher or lower, to account for differences in the voices of individuals.

The code illustrated above shows the final values for the augmentation parameters. They were picked in this manner to account for real world factors that users might encounter when submitting their own voice recordings, while still keeping in mind that the quality of these samples should still be reasonable so that they could be fed to the model. Each of the parameters has a probability of 0.5 of being applied to an augmentation of the original file, so that a mix of these effects can be present in any random augmented file.

## 2.3 Dataset division

In machine learning, datasets are divided into 3 categories: training, validation and testing. This division stands at the base of creating, adjusting and evaluating models.

The training set is used to train the machine learning model, acting as the model’s learning material to determine the underlying patterns and relationships in the data. The process involves the adjustment of the model’s parameters according to the data present in the training set while minimizing losses. It is around 60 to 80% of the entire dataset, after which it is augmented.

The validation set is used to adjust the model’s hyperparameters, which are external to the model but affect the model’s performance, such as the learning rate and the number of epochs. It is around 10 to 20% of the entire dataset.

The testing set is used as a final evaluation of the model, performed on unseen data after training and validation. It is around 10 to 20% of the entire dataset.

The validation and testing sets are not augmented, because validation still needs to be done in comparison with the original samples, where specific traits of speech are not influenced by other parameters, while testing should also be done with the original samples to see if the added parameters to the training dataset did not influence features that could offer the diagnosis.

After dividing the dataset, since the overall number of samples is small, augmentation of the training set is done with the help of the audiomentations library, adding the effect of external factors so that the model could react positively to unseen data, meaning recordings from users that were not done inside a noise controlled environment, possibly with lower quality microphones or devices.


